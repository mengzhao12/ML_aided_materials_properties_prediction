{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mengzhao/miniconda2/envs/1_springboard_ds_track/lib/python3.6/site-packages/pymatgen/io/cif.py:37: UserWarning:\n",
      "\n",
      "Please install optional dependency pybtex if youwant to extract references from CIF files.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pprint\n",
    "import re\n",
    "import requests\n",
    "import io\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pymatgen import MPRester\n",
    "from pymatgen.io.cif import CifBlock,CifFile\n",
    "from pymatgen.core.structure import Structure\n",
    "from pymatgen.core.lattice import Lattice\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_lengthy(f):\n",
    "    \"\"\" count the number of lines in file handle\n",
    "    Parameters\n",
    "    ----------\n",
    "    f : file handle\n",
    "        file to read from\n",
    "    Returns\n",
    "    -------\n",
    "    num_lines : int\n",
    "        returns the number of lines in the file.\n",
    "    --------\n",
    "    \"\"\"   \n",
    "    for i, l in enumerate(f):\n",
    "        pass\n",
    "    return int(i + 1)\n",
    "\n",
    "def read_ase_xyz(fin):\n",
    "    \"\"\" read a xyz file created using ASE from file handle\n",
    "    Parameters\n",
    "    ----------\n",
    "    fin : file handle\n",
    "        file to read from\n",
    "    Returns\n",
    "    -------\n",
    "    lattice_vector: 3*3 numpy matrix\n",
    "    coords: cartesian coordinates of the system natoms*3 array\n",
    "    species: a list of elements in the system\n",
    "    --------\n",
    "    \"\"\"\n",
    "    # count the number of atoms\n",
    "    natoms = file_lengthy(fin) - 6\n",
    "    \n",
    "    # cursor returns to the first line of file   \n",
    "    fin.seek(0)\n",
    "    \n",
    "    # skip the first three lines in ase_xyz file\n",
    "    next(fin)\n",
    "    next(fin)\n",
    "    next(fin)\n",
    "    \n",
    "    lattice_vector = np.zeros([3, 3], dtype=\"float64\")\n",
    "    \n",
    "    for vector in lattice_vector:\n",
    "        line = fin.readline().split()\n",
    "        vector[:] = list(map(float, line[1:4]))\n",
    "\n",
    "    coords = np.zeros([natoms, 3], dtype=\"float64\")\n",
    "    species = []\n",
    "    for x in coords:\n",
    "        line = fin.readline().split()\n",
    "        species.append(line[4])\n",
    "        x[:] = list(map(float, line[1:4]))\n",
    "\n",
    "    return lattice_vector, coords, species\n",
    "\n",
    "def read_pymatgen_cif(stringIO, natoms):\n",
    "    \"\"\" read structure information from string with pymatgen cif format\n",
    "    Parameters\n",
    "    ----------\n",
    "    stringIO : io.StringIO with pymatgen cif format\n",
    "    Returns\n",
    "    -------\n",
    "    lattice_vector: 3*3 numpy matrix\n",
    "    coords: cartesian coordinates of the system natoms*3 array\n",
    "    species: a list of elements in the system\n",
    "    --------\n",
    "    \"\"\"\n",
    "    # count the number of atoms\n",
    "    natoms = file_lengthy(stringIO) - 26\n",
    "    \n",
    "    # cursor returns to the first line of file   \n",
    "    stringIO.seek(0)\n",
    "    \n",
    "    # skip the first three lines in pymatgen_cif file\n",
    "    next(stringIO)\n",
    "    next(stringIO)\n",
    "    next(stringIO)\n",
    "\n",
    "    a = float(stringIO.readline().split()[1])\n",
    "    b = float(stringIO.readline().split()[1])\n",
    "    c = float(stringIO.readline().split()[1])\n",
    "    \n",
    "    alpha = float(stringIO.readline().split()[1])\n",
    "    beta = float(stringIO.readline().split()[1])\n",
    "    gamma = float(stringIO.readline().split()[1])\n",
    "    \n",
    "    lattice_vector = Lattice.from_parameters(a, b, c, alpha, beta, gamma) \n",
    "    lattice_vector_matrix = lattice_vector._matrix\n",
    "    \n",
    "    # skip uncessary rows\n",
    "    for i in range(1,18):\n",
    "        next(stringIO)\n",
    "\n",
    "    coords = np.zeros([natoms, 3], dtype=\"float64\")\n",
    "    species = []\n",
    "    for x in coords:\n",
    "        line = stringIO.readline().split()\n",
    "        species.append(line[0])\n",
    "        x[:] = list(map(float, line[3:6]))\n",
    "\n",
    "    return lattice_vector_matrix, coords, species\n",
    "\n",
    "def read_poscar(fin):\n",
    "    \"\"\" read a poscar file \n",
    "    Parameters\n",
    "    ----------\n",
    "    fin : file handle\n",
    "        file to read from\n",
    "    Returns\n",
    "    -------\n",
    "    lattice_vector: 3*3 numpy matrix\n",
    "    coords: cartesian coordinates of the system natoms*3 array\n",
    "    species: a list of elements in the system\n",
    "    --------\n",
    "    \"\"\"\n",
    "    # count the number of atoms\n",
    "    natoms = file_lengthy(fin) - 8\n",
    "    \n",
    "    # cursor returns to the first line of file   \n",
    "    fin.seek(0)\n",
    "    \n",
    "    # skip the first two lines in poscar\n",
    "    next(fin)\n",
    "    next(fin)\n",
    "    \n",
    "    lattice_vector = np.zeros([3, 3], dtype=\"float64\")\n",
    "    \n",
    "    for vector in lattice_vector:\n",
    "        line = fin.readline().split()\n",
    "        vector[:] = list(map(float, line[0:3]))\n",
    "        \n",
    "    species = []   \n",
    "    species_line = fin.readline().split()\n",
    "    for s in species_line:\n",
    "        species.append(s)\n",
    "        \n",
    "    species_nums = []\n",
    "    species_nums_line = fin.readline().split()\n",
    "    for num in species_nums_line:\n",
    "        species_nums.append(int(num))\n",
    "    \n",
    "    species_corr = []\n",
    "    for index, s in enumerate(species):\n",
    "        for i in range(species_nums[index]):\n",
    "            species_corr.append(s)\n",
    "        \n",
    "    # skip the next one line in poscar\n",
    "    next(fin)      \n",
    "\n",
    "    coords = np.zeros([natoms, 3], dtype=\"float64\")\n",
    "    for x in coords:\n",
    "        line = fin.readline().split()\n",
    "        x[:] = list(map(float, line[0:3]))\n",
    "\n",
    "    return lattice_vector, coords, species_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. gathering and wrangling datasets from NOMAD kaggle repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data_k has 2400 entries in total without any missing value\n",
    "data_k= pd.read_csv('./data_part1/data.csv')\n",
    "data_k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize three lists\n",
    "materials_ids = []\n",
    "stru_list = []\n",
    "formulas = []\n",
    "\n",
    "# convert the geometry.xyz data into a pymatgen structure object\n",
    "for materials_id in data_k[\"id\"]:\n",
    "    with open(\"./data_part1/data/\"+ str(materials_id) + \"/geometry.xyz\") as f:\n",
    "        lattice_vector, coords, species = read_ase_xyz(f)\n",
    "\n",
    "    materials_ids.append(materials_id)\n",
    "    stru = Structure(lattice_vector, species, coords, coords_are_cartesian=True)\n",
    "    formula = stru.composition.reduced_formula\n",
    "    stru_list.append(stru)\n",
    "    formulas.append(formula)\n",
    "\n",
    "stru_df = pd.DataFrame({\"id\":materials_ids,\n",
    "                        \"structure\":stru_list,\n",
    "                        \"formula\":formulas\n",
    "                      })\n",
    "\n",
    "stru_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join data_k and stru_df based on id\n",
    "\n",
    "data_k_processed = data_k.merge(stru_df,on ='id')\n",
    "data_k_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop uncessary columns as structure objects in structure columns contains\n",
    "# information on number of total atoms, percent of atoms, lattices vector, angles and so on\n",
    "\n",
    "data_k_processed = data_k_processed[[\"formula\",\"structure\",\"spacegroup\",\n",
    "                                     \"formation_energy_ev_natom\",\n",
    "                                     \"bandgap_energy_ev\"]]\n",
    "data_k_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. gathering and wrangling datasets from materials project database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"UFIyGHZh8JP5ikew\"\n",
    "\n",
    "# initializes the REST adaptor. Put your own API key in.\n",
    "a = MPRester(api_key)\n",
    " \n",
    "# get entries for desired chemical systems\n",
    "entries_1 = a.get_entries_in_chemsys(['Al','Ga','In','O',\n",
    "                                    'Mo','Zr','W', 'Ta',\n",
    "                                    'Sb','Zn','Sn','Ti',\n",
    "                                    'Ce'])\n",
    "\n",
    "entries_2 = a.get_entries_in_chemsys(['O','Fe','Co','Cu',\n",
    "                                    'Ni','Mn','Pt','Pd',\n",
    "                                    'Ir','Ru'])\n",
    "entries = entries_1 + entries_2\n",
    "\n",
    "# print(entries)\n",
    "mp_ids = []\n",
    "for entry in entries:    \n",
    "    # considering metal oxides at least one metal element contained \n",
    "    if entry.composition.to_data_dict[\"nelements\"] > 1 and 'O' in entry.composition.as_dict().keys():       \n",
    "        mp_ids.append(entry.entry_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a list for storing detailed information of the entries\n",
    "m = []\n",
    "for mp_id in mp_ids:\n",
    "\n",
    "    # get the relavent chemical properties based on the entires of interests\n",
    "    mp_entry = requests.get(\"https://www.materialsproject.org/rest/v2/materials/\"+\n",
    "                             mp_id +\"/vasp?API_KEY=\"+ api_key)\n",
    "    \n",
    "    mp_entry_json = mp_entry.json()\n",
    "    m.append(mp_entry_json['response'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a pandas dataframe using response json data\n",
    "r = pd.DataFrame(m)\n",
    "r_materials = r[['material_id','spacegroup','pretty_formula',\n",
    "                 'unit_cell_formula','cif','band_gap',\n",
    "                 'formation_energy_per_atom']]\n",
    "\n",
    "# extract the spacegroup number of the materials\n",
    "r_materials['spacegroup'] = r_materials['spacegroup'].apply(lambda x: x['number'])\n",
    "\n",
    "# extract number_of_total_atoms of the materials\n",
    "r_materials['number_of_total_atoms'] = r_materials['unit_cell_formula'].apply(lambda x: sum(x.values()))\n",
    "\n",
    "# rename the columns to be consistent with the data_part1 from kaggle\n",
    "r_materials.rename(columns={'formation_energy_per_atom':'formation_energy_ev_natom',\n",
    "                            'band_gap':'bandgap_energy_ev',\n",
    "                            'material_id':'id'}, \n",
    "                            inplace=True)\n",
    "\n",
    "r_materials.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cif_string = r_materials['cif'].tolist()\n",
    "mp_stru_list = []\n",
    "materials_mp_ids = []\n",
    "\n",
    "for index, cif_s in enumerate(cif_string):\n",
    "    \n",
    "    materials_mp_id = r_materials['id'][index]\n",
    "    materials_mp_ids.append(materials_mp_id)\n",
    "    \n",
    "    natoms = r_materials['number_of_total_atoms'][index]\n",
    "    \n",
    "    cif_reading = io.StringIO(cif_s)\n",
    "    lattice_vector,coords, species = read_pymatgen_cif(cif_reading, natoms)\n",
    "    mp_stru = Structure(lattice_vector, species, coords, coords_are_cartesian=False)\n",
    "    mp_stru_list.append(mp_stru)\n",
    "\n",
    "mp_stru_df = pd.DataFrame({\"id\":materials_mp_ids,\n",
    "                           \"structure\":mp_stru_list,\n",
    "                         })\n",
    "mp_stru_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mp_processed = r_materials.merge(mp_stru_df,on ='id')\n",
    "data_mp_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_mp_processed =data_mp_processed[[\"pretty_formula\",\"structure\",\"spacegroup\",\n",
    "                                     \"formation_energy_ev_natom\",\n",
    "                                     \"bandgap_energy_ev\"]]\n",
    "data_mp_processed = data_mp_processed.rename(columns = {'pretty_formula':'formula'})\n",
    "data_mp_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. gathering and wrangling relavent datasets from ICSD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load datasets from icsd\n",
    "data_icsd= pd.read_csv('./data_part3/properties_icsd.txt',sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remain the entries for semiconductors \n",
    "# where the bandgap is larger than 0 but smaller or equal to 3.0 eV\n",
    "# by checking data_icsd_m_bandgaps.info() there is no missing values\n",
    "\n",
    "data_icsd_m_bandgaps = data_icsd[(data_icsd['bandgap'] > 0.0) \n",
    "                                 &(data_icsd['bandgap'] <= 3.0)\n",
    "                                ]\n",
    "\n",
    "# only remains filenames with two target values\n",
    "data_icsd_m_bandgaps = data_icsd_m_bandgaps[['filename','delta_e','bandgap']]\n",
    "\n",
    "# initialize the empty lists\n",
    "stru_icsd_list = []\n",
    "formulas_icsd = []\n",
    "filenames = []\n",
    "spacegroups = []\n",
    "\n",
    "# convert the VASP POSCAR into a pymatgen structure object\n",
    "for f_name in data_icsd_m_bandgaps[\"filename\"]:\n",
    "    with open(\"./data_part3/icsd-all/\"+ str(f_name)) as f:\n",
    "        try:\n",
    "            lattice_vector, coords, species_corr = read_poscar(f)\n",
    "            stru = Structure(lattice_vector, species_corr, coords, coords_are_cartesian=False)\n",
    "            formula = stru.composition.reduced_formula\n",
    "            spacegroup_symbol, international_num= stru.get_space_group_info()\n",
    "            stru_icsd_list.append(stru)\n",
    "            formulas_icsd.append(formula)\n",
    "            spacegroups.append(international_num)\n",
    "            filenames.append(f_name)\n",
    "        except:\n",
    "            print(f_name)\n",
    "\n",
    "stru_icsd_df = pd.DataFrame({\"filename\":filenames,\n",
    "                             \"structure\":stru_icsd_list,\n",
    "                             \"formula\":formulas_icsd,\n",
    "                             \"spacegroup\":spacegroups\n",
    "                           })\n",
    "\n",
    "stru_icsd_df.info()\n",
    "stru_icsd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_icsd_processed = data_icsd_m_bandgaps.merge(stru_icsd_df,on ='filename')\n",
    "data_icsd_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_icsd_processed = data_icsd_processed[[\"formula\",\"structure\",\"spacegroup\",\n",
    "                                           \"delta_e\",\"bandgap\"]]\n",
    "data_icsd_processed = data_icsd_processed.rename(columns = {'delta_e':'formation_energy_ev_natom',\n",
    "                                                        'bandgap':'bandgap_energy_ev'})\n",
    "data_icsd_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. gathering and wrangling datasets from OQMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_oqmd = pd.read_csv('./data_part3/properties_oqmd.txt',sep=' ')\n",
    "\n",
    "# OQMD dataset contains 'None' strings\n",
    "data_oqmd = data_oqmd.replace('None', np.nan)\n",
    "data_oqmd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bandgap column in OQMD has the missing values\n",
    "# we will emlimate those entries as bandgap is one of the target values\n",
    "\n",
    "# elimintate entries with missing bandgaps in oqmd\n",
    "data_oqmd = data_oqmd.dropna()\n",
    "\n",
    "# convert bandgap columns to the type of float\n",
    "data_oqmd['bandgap'] = data_oqmd['bandgap'].astype(float)\n",
    "\n",
    "# remain the semiconductors where the bandgap is larger than 0 but smaller or equal to 3.0 eV\n",
    "data_oqmd_m_bandgaps = data_oqmd[(data_oqmd['bandgap'] > 0.0) \n",
    "                                 &(data_oqmd['bandgap'] <= 3.0)\n",
    "                                ]\n",
    "# only remains filenames with two target values\n",
    "data_oqmd_m_bandgaps = data_oqmd_m_bandgaps[['filename','delta_e','bandgap']]\n",
    "\n",
    "# initialize the empty lists\n",
    "stru_oqmd_list = []\n",
    "formulas_oqmd = []\n",
    "filenames_oqmd = []\n",
    "spacegroups_oqmd = []\n",
    "\n",
    "# convert the VASP POSCAR into a pymatgen structure object\n",
    "for f_name in data_oqmd_m_bandgaps[\"filename\"]:\n",
    "    with open(\"./data_part3/oqmd-all/\"+ str(f_name)) as f:\n",
    "        try:\n",
    "            lattice_vector, coords, species_corr = read_poscar(f)\n",
    "            stru = Structure(lattice_vector, species_corr, coords, coords_are_cartesian=False)\n",
    "            formula = stru.composition.reduced_formula\n",
    "            spacegroup_symbol, international_num= stru.get_space_group_info()\n",
    "            stru_oqmd_list.append(stru)\n",
    "            formulas_oqmd.append(formula)\n",
    "            spacegroups_oqmd.append(international_num)\n",
    "            filenames_oqmd.append(f_name)\n",
    "        except:\n",
    "            print(f_name)\n",
    "\n",
    "stru_oqmd_df = pd.DataFrame({\"filename\":filenames_oqmd,\n",
    "                             \"structure\":stru_oqmd_list,\n",
    "                             \"formula\":formulas_oqmd,\n",
    "                             \"spacegroup\":spacegroups_oqmd\n",
    "                           })\n",
    "\n",
    "stru_oqmd_df.info()\n",
    "stru_oqmd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_oqmd_processed = data_oqmd_m_bandgaps.merge(stru_oqmd_df,on ='filename')\n",
    "data_oqmd_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_oqmd_processed = data_oqmd_processed[[\"formula\",\"structure\",\"spacegroup\",\n",
    "                                           \"delta_e\",\"bandgap\"]]\n",
    "data_oqmd_processed = data_oqmd_processed.rename(columns = {'delta_e':'formation_energy_ev_natom',\n",
    "                                                            'bandgap':'bandgap_energy_ev'})\n",
    "data_oqmd_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. concatenate four datasets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_k_processed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d6d127108fb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# concatenate two datasets data_k_processed and data_mp_processed together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_k_processed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_mp_processed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_icsd_processed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_oqmd_processed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdata_complete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_k_processed' is not defined"
     ]
    }
   ],
   "source": [
    "# concatenate two datasets data_k_processed and data_mp_processed together\n",
    "\n",
    "frames = [data_k_processed,data_mp_processed,data_icsd_processed,data_oqmd_processed]\n",
    "data_complete = pd.concat(frames)\n",
    "\n",
    "data_complete.head()\n",
    "data_complete.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. data explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boxplot = data_complete.boxplot(column=['formation_energy_ev_natom',\n",
    "                                        'bandgap_energy_ev'])\n",
    "plt.ylabel(\"energy in eV\")\n",
    "plt.title(\"Figure 1. boxplot of formation_energy_ev_natom and bandgap_energy_ev\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# found two outliers which have unrelistic formaiton energies \n",
    "# we decide to drop these two entries\n",
    "data_complete[data_complete['formation_energy_ev_natom'] > 250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete = data_complete[data_complete['formation_energy_ev_natom'] < 250]\n",
    "\n",
    "# box plot after removing two outliers\n",
    "boxplot = data_complete.boxplot(column=['formation_energy_ev_natom',\n",
    "                                        'bandgap_energy_ev'])\n",
    "plt.ylabel(\"energy in eV\")\n",
    "plt.title(\"Figure 2. boxplot of formation_energy_ev_natom and bandgap_energy_ev\\n\" +\n",
    "          \"after removing two outliers\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matminer.featurizers.conversions import StrToComposition,CompositionToOxidComposition\n",
    "from matminer.featurizers.composition import ElementProperty,OxidationStates\n",
    "from matminer.featurizers.structure import DensityFeatures\n",
    "\n",
    "# features\n",
    "X = data_complete[['formula','structure','spacegroup']]\n",
    "X_formula_feat = StrToComposition().featurize_dataframe(X, \"formula\")\n",
    "X_formula_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. save datasets into CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the proceessed complete dataset into a csv file \n",
    "data_complete.to_csv(\"./data_complete.csv\", sep=',') \n",
    "\n",
    "# save the proceessed dataset separately into a csv file \n",
    "data_k_processed.to_csv(\"./data_k_processed.csv\", sep=',') \n",
    "data_mp_processed.to_csv(\"./data_mp_processed.csv\", sep=',') \n",
    "data_icsd_processed.to_csv(\"./data_icsd_processed.csv\", sep=',') \n",
    "data_oqmd_processed.to_csv(\"./data_oqmd_processed.csv\", sep=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timer\n",
    "end = time.time()\n",
    "print(\"The data processing time is \" + str((end-start)/3600) + \" hours.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py36_kernel",
   "language": "python",
   "name": "envname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
